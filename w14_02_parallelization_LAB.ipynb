{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Ironhack logo](https://i.imgur.com/1QgrNNw.png)\n",
    "\n",
    "# Lab | Parallelization\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This lab will combine parallelization with some of the other topics you have learned in the Intermediate Python module of this program (list comprehensions, requests library, functional programming, web scraping, etc.). You will write code that extracts a list of links from a web page, requests each URL, and then indexes the page referenced by each link - both sequentially and in parallel.\n",
    "\n",
    "## Resources\n",
    "\n",
    "- [Multiprocessing Library Documentation](https://docs.python.org/3/library/multiprocessing.html?highlight=multiprocessing#module-multiprocessing)\n",
    "- [Python Parallel Computing (in 60 Seconds or less)](https://dbader.org/blog/python-parallel-computing-in-60-seconds)\n",
    "- [Python Multiprocessing: Pool vs Process â€“ Comparative Analysis](https://www.ellicium.com/python-multiprocessing-pool-process/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Use the requests library to retrieve the content from the URL below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HlQZvSUqSEjn"
   },
   "outputs": [],
   "source": [
    "\n",
    "url = 'https://en.wikipedia.org/wiki/Data_science'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dHlgfatrSEjs"
   },
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "html = response.content\n",
    "soup = BeautifulSoup(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ig5G0TTDSEjw"
   },
   "source": [
    "## Step 2: Use BeautifulSoup to extract a list of all the unique links on the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zahpf2s-SEjx"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = soup.find_all('a', href=True)\n",
    "unique_links = list(set([link['href'] for link in links]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i7TXSNXCSEj3"
   },
   "source": [
    "## Step 3: Use list comprehensions with conditions to clean the link list.\n",
    "\n",
    "Create a list with the absolute link and remove any that contain a percentage sign (%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHDkpTrISEj7"
   },
   "outputs": [],
   "source": [
    "absolute_links = [link for link in unique_links if link.startswith('http') and '%' not in link]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://es.wikipedia.org/wiki/Ciencia_de_datos',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Data_science&oldid=1051586722',\n",
       " 'https://nl.wikipedia.org/wiki/Datawetenschap',\n",
       " 'https://wikimediafoundation.org/',\n",
       " 'https://statmodeling.stat.columbia.edu/2013/11/14/statistics-least-important-part-data-science/',\n",
       " 'https://www.forbes.com/sites/gilpress/2013/05/28/a-very-short-history-of-data-science/',\n",
       " 'https://magazine.amstat.org/blog/2016/06/01/datascience-2/',\n",
       " 'https://web.archive.org/web/20140102194117/http://simplystatistics.org/2013/12/12/the-key-word-in-data-science-is-not-data-it-is-science/',\n",
       " 'https://books.google.com/books?id=oGs_AQAAIAAJ',\n",
       " 'https://fi.wikipedia.org/wiki/Datatiede',\n",
       " 'https://towardsdatascience.com/how-data-science-will-impact-future-of-businesses-7f11f5699c4d',\n",
       " 'https://magazine.amstat.org/blog/2015/10/01/asa-statement-on-the-role-of-statistics-in-data-science/',\n",
       " 'https://www.oreilly.com/library/view/doing-data-science/9781449363871/ch01.html',\n",
       " 'https://www.springer.com/book/9784431702085',\n",
       " 'https://foundation.wikimedia.org/wiki/Cookie_statement',\n",
       " 'https://foundation.wikimedia.org/wiki/Privacy_policy',\n",
       " 'https://flowingdata.com/2009/06/04/rise-of-the-data-scientist/',\n",
       " 'https://cs.wikipedia.org/wiki/Data_science',\n",
       " 'https://stats.wikimedia.org/#/en.wikipedia.org',\n",
       " 'https://www.mediawiki.org/',\n",
       " 'http://courses.csail.mit.edu/18.337/2015/docs/50YearsDataScience.pdf',\n",
       " 'https://www.wikidata.org/wiki/Special:EntityPage/Q2374463',\n",
       " 'https://et.wikipedia.org/wiki/Andmeteadus',\n",
       " 'https://eu.wikipedia.org/wiki/Datu_zientzia',\n",
       " 'https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century/',\n",
       " 'https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute',\n",
       " 'https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century',\n",
       " 'https://www.nsf.gov/pubs/2005/nsb0540/',\n",
       " 'http://www2.isye.gatech.edu/~jeffwu/presentations/datascience.pdf',\n",
       " 'http://www.datascienceassn.org/about-data-science',\n",
       " 'https://pl.wikipedia.org/wiki/Danologia',\n",
       " 'https://commons.wikimedia.org/wiki/Category:Data_science',\n",
       " 'https://web.archive.org/web/20170320193019/https://books.google.com/books?id=oGs_AQAAIAAJ',\n",
       " 'https://eo.wikipedia.org/wiki/Datuma_scienco',\n",
       " 'https://www2.isye.gatech.edu/~jeffwu/publications/fazhan.pdf',\n",
       " 'https://www.wikidata.org/wiki/Special:EntityPage/Q2374463#sitelinks-wikipedia',\n",
       " 'http://cacm.acm.org/magazines/2013/12/169933-data-science-and-prediction/fulltext',\n",
       " 'https://medriscoll.com/post/4740157098/the-three-sexy-skills-of-data-geeks',\n",
       " 'https://www.forbes.com/sites/gilpress/2013/08/19/data-science-whats-the-half-life-of-a-buzzword/',\n",
       " 'https://ms.wikipedia.org/wiki/Sains_data',\n",
       " 'http://priceonomics.com/whats-the-difference-between-data-science-and/',\n",
       " 'https://web.archive.org/web/20190620184935/https://magazine.amstat.org/blog/2015/10/01/asa-statement-on-the-role-of-statistics-in-data-science/',\n",
       " 'https://it.wikipedia.org/wiki/Scienza_dei_dati',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Template:Machine_learning&action=edit',\n",
       " 'https://api.semanticscholar.org/CorpusID:6107147',\n",
       " 'https://api.semanticscholar.org/CorpusID:9743327',\n",
       " 'https://web.archive.org/web/20141109113411/http://cacm.acm.org/magazines/2013/12/169933-data-science-and-prediction/fulltext',\n",
       " 'http://simplystatistics.org/2013/12/12/the-key-word-in-data-science-is-not-data-it-is-science/',\n",
       " 'https://benfry.com/phd/dissertation/2.html',\n",
       " 'https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en',\n",
       " 'https://de.wikipedia.org/wiki/Data_Science',\n",
       " 'https://tr.wikipedia.org/wiki/Veri_bilimi',\n",
       " 'https://www.forbes.com/sites/peterpham/2015/08/28/the-impacts-of-big-data-that-you-may-not-have-heard-of/',\n",
       " 'https://www.stat.purdue.edu/~wsc/',\n",
       " 'https://id.wikipedia.org/wiki/Ilmu_data',\n",
       " 'https://www.statisticsviews.com/article/nate-silver-what-i-need-from-statisticians/',\n",
       " 'https://arxiv.org/list/cs.LG/recent',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Template:Data&action=edit',\n",
       " 'https://simple.wikipedia.org/wiki/Data_science']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absolute_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "liPZ-FYLSEkA"
   },
   "source": [
    "## Step 4: Write a function called crawl_page that accepts a link and does the following.\n",
    "\n",
    "- Request the content of the page referenced by that link.\n",
    "- Create a soup with the request content.\n",
    "- Extract a list of links\n",
    "- Return the count of links in the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jErdx2cdSEkD"
   },
   "outputs": [],
   "source": [
    "def crawl_page(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    \n",
    "    html = requests.get(url).content\n",
    "    soup = BeautifulSoup(html)\n",
    "    link_list = soup.find_all('a', href=True)\n",
    "    return len(link_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "475"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crawl_page(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qyDm2n-rSEkG"
   },
   "source": [
    "## Step 5: Sequentially loop through the list of links, running the crawl_page function each time and save result in a list.\n",
    "\n",
    "Remember to include `%%time` at the beginning of the cell so that it measures the time it takes for the cell to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mm7-pzw4SEkK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[275, 489, 128, 100, 0, 331, 4, 67, 151, 119, 76, 4, 69, 54, 71, 369, 113, 363, 0, 171, 0, 162, 298, 229, 176, 279, 176, 146, 0, 10, 116, 226, 172, 100, 0, 162, 1, 39, 287, 140, 80, 70, 189, 99, 126, 115, 157, 21, 2, 27, 362, 258, 279, 5, 272, 1, 237, 83, 125]\n",
      "CPU times: user 12.7 s, sys: 234 ms, total: 13 s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_list = []\n",
    "\n",
    "for url in absolute_links:\n",
    "    result_list.append(crawl_page(url))\n",
    "\n",
    "print(result_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VVDNEdyVSEkM"
   },
   "source": [
    "## Step 6: Sequentially loop through the list of links, running the index_page function each time.\n",
    "\n",
    "Remember to include `%%time` at the beginning of the cell so that it measures the time it takes for the cell to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1akpUc5_SEkN"
   },
   "outputs": [],
   "source": [
    "# import multiprocessing\n",
    "\n",
    "import multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[275, 489, 128, 100, 0, 330, 4, 67, 151, 119, 76, 4, 69, 54, 71, 369, 113, 363, 0, 171, 0, 162, 298, 229, 176, 279, 176, 146, 0, 10, 116, 226, 172, 100, 0, 162, 1, 39, 287, 140, 80, 70, 189, 99, 130, 115, 157, 21, 2, 32, 362, 258, 279, 5, 272, 1, 237, 83, 125]\n",
      "CPU times: user 29.5 ms, sys: 57.8 ms, total: 87.3 ms\n",
      "Wall time: 12.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pool = multiprocess.Pool()\n",
    "result = pool.map(crawl_page, absolute_links)\n",
    "pool.terminate()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
